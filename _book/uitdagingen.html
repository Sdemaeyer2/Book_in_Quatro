<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang=""><head>
  <meta charset="utf-8">
  <meta name="generator" content="quarto-0.2.405">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title>De kwaliteit van grootschalige ‘performance assessments’ gewikt en gewogen - 6&nbsp; Uitdagingen voor grootschalige toetsen die ‘performance assessment’ inschakelen</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>

  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script src="site_libs/quarto-nav/quarto-nav.js"></script>
  <script src="site_libs/quarto-nav/headroom.min.js"></script>
  <script src="site_libs/clipboard/clipboard.min.js"></script>
  <meta name="quarto:offset" content="./">
  <script src="site_libs/quarto-search/autocomplete.umd.js"></script>
  <script src="site_libs/quarto-search/fuse.min.js"></script>
  <script src="site_libs/quarto-search/quarto-search.js"></script>
  <link href="./implicaties.html" rel="next">
  <link href="./evaluatiematrix.html" rel="prev">
  <script src="site_libs/quarto-html/quarto.js"></script>
  <script src="site_libs/quarto-html/popper.min.js"></script>
  <script src="site_libs/quarto-html/tippy.umd.min.js"></script>
  <script src="site_libs/quarto-html/anchor.min.js"></script>
  <link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
  <link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet">
  <script src="site_libs/bootstrap/bootstrap.min.js"></script>
  <link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
  <link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
  <script id="quarto-search-options" type="application/json">{
    "location": "sidebar",
    "copy-button": false,
    "collapse-after": 2,
    "panel-placement": "start",
    "type": "textbox",
    "limit": 20,
    "language": {
      "search-no-results-text": "No results",
      "search-matching-documents-text": "matching documents",
      "search-copy-link-title": "Copy link to search",
      "search-hide-matches-text": "Hide additional matches",
      "search-more-match-text": "more match in this document",
      "search-more-matches-text": "more matches in this document",
      "search-clear-button-title": "Wis",
      "search-detached-cancel-button-title": "Cancel",
      "search-submit-button-title": "Submit"
    }
  }</script>
</head>
<body class="docked">
<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Uitdagingen voor grootschalige toetsen die ‘performance assessment’ inschakelen</span></h1>
      <button type="button" class="quarto-btn-toggle btn">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation docked overflow-auto">
  <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
    <img src="./edubron-nl-rgb.jpg" alt="" class="sidebar-logo py-0 d-lg-inline d-none">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">De kwaliteit van grootschalige ‘performance assessments’ gewikt en gewogen</a> 
        <div class="sidebar-tools-main">
    <a href="" title="Download" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-download"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="./De-kwaliteit-van-grootschalige-‘performance-assessments’-gewikt-en-gewogen.docx">
            <i class="bi bi-bi-file-word pe-1"></i>
          Download Docx
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="./De-kwaliteit-van-grootschalige-‘performance-assessments’-gewikt-en-gewogen.pdf">
            <i class="bi bi-bi-file-pdf pe-1"></i>
          Download PDF
          </a>
        </li>
    </ul>
    <a href="" title="Share" id="sidebar-tool-dropdown-1" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-1">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
    </ul>
</div>
    </div>
  </div>
    <div class="mt-2 flex-shrink-0 align-items-center">
      <div class="sidebar-search">
      <div id="quarto-search" class="" title="Search"></div>
      </div>
    </div>
  <div class="sidebar-menu-container"> 
  <ul class="list-unstyled mt-1">
      <li class="sidebar-item">
  <a href="./index.html" class="">Voorwoord</a>
</li>
      <li class="sidebar-item">
  <a href="./intro.html" class=""><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Ten Geleide</span></a>
</li>
      <li class="sidebar-item">
  <a href="./probleemstelling.html" class=""><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Probleemstelling en Begrippenkader</span></a>
</li>
      <li class="sidebar-item">
  <a href="./Ontwikkeling_matrix.html" class=""><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ontwikkeling van de evaluatiematrix</span></a>
</li>
      <li class="sidebar-item">
  <a href="./buitenlandse_voorbeelden.html" class=""><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Buitenlandse voorbeelden van grootschalige ‘performance assessments’</span></a>
</li>
      <li class="sidebar-item">
  <a href="./evaluatiematrix.html" class=""><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Evaluatiematrix</span></a>
</li>
      <li class="sidebar-item">
  <a href="./uitdagingen.html" class="active"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Uitdagingen voor grootschalige toetsen die ‘performance assessment’ inschakelen</span></a>
</li>
      <li class="sidebar-item">
  <a href="./implicaties.html" class=""><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Implicaties</span></a>
</li>
      <li class="sidebar-item">
  <a href="./woordenlijst.html" class="">Woordenlijst</a>
</li>
      <li class="sidebar-item">
  <a href="./references.html" class="">Referenties</a>
</li>
  </ul>
  </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
      <nav id="TOC" role="doc-toc">
<h2 id="toc-title">Inhoud hoofdstuk</h2>
<ul>
<li><a href="#uitdaging-1-voldoende-taken-voorzien" class="nav-link active" data-scroll-target="#uitdaging-1-voldoende-taken-voorzien"> <span class="header-section-number">6.1</span> Uitdaging 1: Voldoende taken voorzien</a></li>
<li><a href="#uitdaging-2-standaardisering-van-toetsafname-en-scoren" class="nav-link" data-scroll-target="#uitdaging-2-standaardisering-van-toetsafname-en-scoren"> <span class="header-section-number">6.2</span> Uitdaging 2: Standaardisering van toetsafname en scoren</a></li>
<li><a href="#uitdaging-3-vermijden-van-construct-irrelevante-variantie" class="nav-link" data-scroll-target="#uitdaging-3-vermijden-van-construct-irrelevante-variantie"> <span class="header-section-number">6.3</span> Uitdaging 3: Vermijden van construct-irrelevante variantie</a></li>
<li><a href="#uitdaging-4-het-opzetten-van-taken-die-recht-doen-aan-de-criteriumsituatie" class="nav-link" data-scroll-target="#uitdaging-4-het-opzetten-van-taken-die-recht-doen-aan-de-criteriumsituatie"> <span class="header-section-number">6.4</span> Uitdaging 4: Het opzetten van taken die recht doen aan de criteriumsituatie</a></li>
<li><a href="#uitdaging-5-conform-de-doelstellingen-rapporteren" class="nav-link" data-scroll-target="#uitdaging-5-conform-de-doelstellingen-rapporteren"> <span class="header-section-number">6.5</span> Uitdaging 5: Conform de doelstellingen rapporteren</a></li>
</ul>
</nav>
    </div>
<!-- main -->
<main class="content">
<header id="title-block-header">
<h1 class="title d-none d-lg-block display-7"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Uitdagingen voor grootschalige toetsen die ‘performance assessment’ inschakelen</span></h1>
</header>

<p>De systematische literatuurstudie in combinatie met een doorgedreven analyse van internationale praktijkvoorbeelden, stelden ons in staat de meest cruciale uitdagingen van grootschalige evaluatie van competenties op grond van ‘performance assessment’ in kaart te brengen. De geraadpleegde bronnen gaven bovendien inzicht in mogelijke werkwijzen en oplossingen die een antwoord bieden op deze uitdagingen. Hieronder vatten we beknopt samen over welke uitdagingen het gaat en welke alternatieve oplossingen zich kunnen aandienen.</p>
<section id="uitdaging-1-voldoende-taken-voorzien" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="uitdaging-1-voldoende-taken-voorzien"><span class="header-section-number">6.1</span> Uitdaging 1: Voldoende taken voorzien</h2>
<p>Een toets waarbij gebruik wordt gemaakt van ‘performance assessment’, moet een voldoende groot aantal verschillende taken omvatten om tot betrouwbare en valide conclusies te leiden. Dan pas kunnen scores gegeneraliseerd worden overheen verschillende taken uit de ontwikkelde pool van taken (zie ook 3.1.) in plaats van louter toegeschreven worden aan een enkele uitgevoerde taak.</p>
<p>Aan de basis van de noodzaak om meerdere taken in te zetten liggen enerzijds de tussen-takenvariabiliteit en anderzijds het brede domein dat een competentietoets vaak moet bestrijken. De tussen-takenvariabiliteit (‘task sampling variability’) houdt in dat prestaties van leerlingen substantieel variëren tussen taken, omwille van de unieke kenmerken van de taak en de interactie van deze kenmerken met de kennis en ervaring van de leerling <span class="citation" data-cites="nationalresearchcouncilDeveloping2014">National Research Council (<a href="references.html#ref-nationalresearchcouncilDeveloping2014" role="doc-biblioref">2014</a>)</span>. Om een hypothetisch voorbeeld te geven: het geven van een presentatie en de vaardigheid om dit te doen, kan sterk variëren naargelang het onderwerp waarover het moet gaan. Of het onderwerp aansluit bij de persoonlijke levenssfeer of interesse van de leerling kan de uiteindelijke prestatie sterk beïnvloeden. Uit de geraadpleegde literatuur blijkt dat de tussen-takenvariabiliteit een van de facetten is die het meeste bijdraagt tot de <span class="citation" data-cites="shavelsonMeasurement2010">(<a href="references.html#ref-shavelsonMeasurement2010" role="doc-biblioref">Shavelson 2010</a>)</span>. Tussen-takenvariabiliteit is een belangrijkere bron van meetfouten dan tussen-beoordelaarsvariabiliteit. Of anders gesteld: het aantal taken heeft een groter effect op de generaliseerbaarheid van scores dan het aantal beoordelaars <span class="citation" data-cites="brennan1995">(<a href="references.html#ref-brennan1995" role="doc-biblioref">Brennan and Johnson 1995</a>)</span>. De mogelijkheid tot generaliseren van scores wordt bijgevolg groter naarmate er meer performance taken worden voorzien. De nood aan voldoende taken wordt ook ingegeven door het feit dat het domein dat toetsen met het oog op systeemmonitoring dienen te bestrijken, doorgaans veel breder is dan dat van toetsen binnen de klascontext <span class="citation" data-cites="nationalresearchcouncilDeveloping2014">(<a href="references.html#ref-nationalresearchcouncilDeveloping2014" role="doc-biblioref">National Research Council 2014</a>)</span>. Het domein ‘informatieverwerving en –verwerking’ bijvoorbeeld is erg ruim en omvat zowel het zelfstandig en op systematische wijze gebruiken van verschillende informatiebronnen, als het systematisch verwerven en gebruiken van samenhangende informatie (ook andere dan teksten). Een toets samenstellen die representatief zou zijn voor dit beoogde domein, kan doorgaans alleen indien er voldoende taken worden voorzien. Immers, hoe minder taken, hoe minder mogelijkheden er zijn om het beoogde domein volledig te bestrijken.</p>
<p>Praktisch is het afnemen van meerdere ‘performance assessment’-taken echter een grote uitdaging door de vereiste inzet van middelen die dit met zich meebrengt. Een ‘performance assessment’-taak is vaak complex, wat maakt dat de afname ingewikkelder is en het ook langer duurt om de taak af te ronden. Indien men ernaar streeft om de toetsduur niet al te sterk te verlengen, betekent dit dat er een grens is aan hoeveel ‘performance assessment’-taken men een leerling kan voorleggen. Het terugvallen op een beperktere set ‘performance assessment’-taken verhoogt echter weer het risico op een grote(re) meetfout en heeft een negatieve impact op de mogelijkheid tot generaliseren:</p>
<blockquote class="blockquote">
<p>Many authors have observed that limited sampling of relevant performances from a target domain, owing to issues of practicality, safety and fairness as well as the complexity and/or length of the performance tasks, poses the main challenge for the validity of performance assessment in particular. <span class="citation" data-cites="curcinValidation2014">(<a href="references.html#ref-curcinValidation2014" role="doc-biblioref">Curcin et al. 2014, 40</a>)</span></p>
</blockquote>
<p>Uit onze analyse van de praktijkvoorbeelden blijkt dat men doorgaans enkele honderden items en/of taken nodig heeft om een voldoende dekking van het brede, complexe toetsraamwerk te verzekeren. Bij een authentieke, thematische insteek is bovendien sowieso een ruim aantal taken nodig omdat gebruik gemaakt wordt van realistische scenario’s. De set taken moet daarbij een verhaal helpen neerzetten dat betekenisvol is voor de leerlingen (zie 5.2.4 voor een illustratie vanuit een praktijkvoorbeeld).</p>
<p>Samenvattend kunnen we stellen dat toetsen met het oog op systeemmonitoring vaak een breed domein moeten bestrijken. Dit leidt er, in combinatie met het fenomeen van de tussen-taken-variabiliteit, toe dat deze toetsen een aanzienlijk aantal taken dienen te omvatten om valide en betrouwbare toetsscores op te leveren. Dit is echter praktisch vaak niet haalbaar in termen van kosten voor de ontwikkeling van de toets, de tijd die leerlingen moeten spenderen aan de toets, en de tijd die gaat kruipen in het scoren van de performances. Haalbare en kwaliteitsvolle werkwijzen die op deze problematiek inspelen, die in de praktijkvoorbeelden en de wetenschappelijke literatuur aan bod kwamen, zijn (zie 5.2.3.):</p>
<ul>
<li>het inperken van het competentiedomein naar het toetsdomein via een kwaliteitsvolle domeinbeschrijving;</li>
<li>het inzetten van matrix-sampling;</li>
<li>het voorzien van verschillende item-formats in één toets;</li>
<li>het inzetten van toetsen die meer ingebed zijn in het klasgebeuren.</li>
</ul>
</section>
<section id="uitdaging-2-standaardisering-van-toetsafname-en-scoren" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="uitdaging-2-standaardisering-van-toetsafname-en-scoren"><span class="header-section-number">6.2</span> Uitdaging 2: Standaardisering van toetsafname en scoren</h2>
<p>Scores van toetsen zijn onderhevig aan meetfouten. Toevallige meetfouten kunnen enerzijds onder controle gehouden worden door de steekproef te vergroten (zie 6.1.), anderzijds door de meetprocedure te standaardiseren. Wat dit tweede aspect betreft, is het met het oog op de vergelijkbaarheid van de interpretaties die aan de scores gehecht worden, noodzakelijk dat dezelfde gedetailleerde procedures gevolgd worden op vlak van richtlijnen, omstandigheden van de toets en scoren <span class="citation" data-cites="aeraStandards2014">(<a href="references.html#ref-aeraStandards2014" role="doc-biblioref">AERA APA &amp; NCME 2014</a>)</span>.</p>
<p>Standaardisering is een kwestie die bij alle (grootschalige) toetsen aan de orde is, ook toetsen die geen gebruik maken van ‘performance assessment’. Eigen aan ‘performance assessment’ is echter dat het grote(re) risico’s op variabiliteit ten gevolge van de toetsafname en het scoren van de ‘performance assessment’-taken in zich draagt. Op het vlak van toetsafname heeft dit bijvoorbeeld te maken met de grotere complexiteit van de taken in vergelijking met een toets die bestaat uit meerkeuzevragen en het risico dat leerlingen op de ene locatie meer begeleiding krijgen bij het oplossen van de taak dan elders. In dat geval heeft standaardisering (of het gebrek eraan) dus gevolgen op vlak van vergelijkbaarheid. Nog een uitdaging komt voort uit het feit dat ‘performance assessment’ vaak bestaat uit open opdrachten en dat de producten die uit deze opdracht ontstaan zo uiteenlopend zijn dat het het scoringsproces bemoeilijkt en de resultaten niet of minder vergelijkbaar zijn <span class="citation" data-cites="stecherLooking2015">(<a href="references.html#ref-stecherLooking2015" role="doc-biblioref">Stecher 2015</a>)</span>. Omwille van de complexiteit van de taken is het daarenboven in het geval van ‘performance assessment’ moeilijker om voldoende consistent en accuraat te scoren <span class="citation" data-cites="johnsonAssessing2009 shavelsonMeasurement2010">(<a href="references.html#ref-johnsonAssessing2009" role="doc-biblioref">Johnson, Penny, and Gordon 2009</a>; <a href="references.html#ref-shavelsonMeasurement2010" role="doc-biblioref">Shavelson 2010</a>)</span>. Naarmate beoordelaars de beoordelingscriteria verschillend toepassen wordt er ‘judgement uncertainty’ geïntroduceerd <span class="citation" data-cites="nationalresearchcouncilDeveloping2014">(<a href="references.html#ref-nationalresearchcouncilDeveloping2014" role="doc-biblioref">National Research Council 2014</a>)</span>. Beoordelaars hebben de neiging doorheen de tijd minder consistent te gaan beoordelen (‘rater drift’) <span class="citation" data-cites="shavelsonMeasurement2010">(<a href="references.html#ref-shavelsonMeasurement2010" role="doc-biblioref">Shavelson 2010</a>)</span>. Ook hier kan standaardisering een oplossing bieden.</p>
<p>Net omwille van de aard van ‘performance assessment’, is het standaardiseren van de toetsafname en het proces van scoren en beoordelen dus niet zomaar eenvoudig geklaard. Daar komt bovenop dat aangereikte oplossingen om de vergelijkbaarheid van scores te garanderen ook haalbaar moeten zijn; een kwestie die zeker bij grootschalige toetsen opspeelt. Kwaliteitsvolle werkwijzen om de toetsafname te standaardiseren, die in de praktijkvoorbeelden aan bod kwamen (zie ook 5.2.4.) zijn: - het lokaal inzetten van centraal getrainde toetsassistenten (duur en logistiek vaak omslachtig) of van lokale leerkrachten (in combinatie met centraal aangestuurde controle en kwaliteitszorg); - het terugvallen op digitale systemen die de omgeving waarin leerlingen hun toets afleggen duidelijk af te bakenen en tegelijkertijd een rijkere en meer authentieke context bieden.</p>
<p>Met betrekking tot het beperken van het risico op beoordelaarseffecten reiken empirische studies o.a. volgende oplossingen aan (zie ook 5.2.5.):</p>
<ul>
<li>het voorzien van een degelijke training aan de beoordelaars;</li>
<li>het inzetten van verschillende beoordelaars;</li>
<li>het zodanig ontwerpen van taken, o.a. op grond van een ‘evidence centered design’ (5.2.3.), dat ze consistent gescoord kunnen worden;</li>
<li>het zodanig ontwerpen van scoringstools (analytische, dan wel holistische) dat ze dit proces ondersteunen.</li>
</ul>
<p>Niet al deze oplossingen zijn evenwel haalbaar in termen van middelen en tijd. Het trainen van beoordelaars of de ontwikkeling van eenduidige scoringstools zijn dure en tijdrovende activiteiten; het samenbrengen van beoordelaars en hen aansturen van op afstand brengt vergelijkbare uitdagingen met zich mee. Ook het inzetten van meerdere beoordelaars leidt tot een verhoging van kosten en tijd. Vanuit deze context bieden zich alternatieve denkrichtingen aan. Paarsgewijze vergelijking lijkt een valide, betrouwbaar en haalbaar alternatief te zijn voor klassiek scoren via rubrics, zeker in combinatie met nieuwe technologische mogelijkheden <span class="citation" data-cites="lesterhuisCompententies2015 lesterhuisComparative2017 vandaalValidity2019b">(<a href="references.html#ref-lesterhuisCompententies2015" role="doc-biblioref">Lesterhuis et al. 2015</a>, <a href="references.html#ref-lesterhuisComparative2017" role="doc-biblioref">2017</a>; <a href="references.html#ref-vandaalValidity2019b" role="doc-biblioref">van Daal et al. 2019</a>)</span>. Geautomatiseerd scoren doet omwille van een verhoogde efficiëntie zijn intrede, met name bij het beoordelen van schrijfproducten. Niet iedereen is er, vanuit validiteitsoogpunt, echter van overtuigd dat deze laatste werkwijze aan te bevelen is. Net als bij de toetsafname wordt in sommige praktijkvoorbeelden geopteerd om de eigen leerkrachten in te zetten voor het beoordelen. Extra waakzaamheid is dan wel geboden in verband met het optreden van beoordelaarseffecten. Onderzoek lijkt evenwel aan te tonen dat ook hier oplossingen voor kunnen worden geboden, onder andere door systematisch in te zetten op het professionaliseren van leerkrachten.</p>
</section>
<section id="uitdaging-3-vermijden-van-construct-irrelevante-variantie" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="uitdaging-3-vermijden-van-construct-irrelevante-variantie"><span class="header-section-number">6.3</span> Uitdaging 3: Vermijden van construct-irrelevante variantie</h2>
<p>Construct-irrelevante variantie (CIV) treedt op als naast het construct dat men beoogt te meten, nog één of meerdere andere constructen worden gemeten <span class="citation" data-cites="messickValidity1989 messickInterplay1994">(<a href="references.html#ref-messickValidity1989" role="doc-biblioref">S. Messick 1989</a>; <a href="references.html#ref-messickInterplay1994" role="doc-biblioref">Samuel Messick 1994</a>)</span>. Als een leerling er bijvoorbeeld niet in slaagt om een bepaalde wiskundetaak op te lossen, kan dit het resultaat zijn van het feit dat de taak ook de competentie ‘begrijpend lezen’ meet. Het zorgt ervoor dat er systematische ruis in de scores van de toets wordt geïntroduceerd.</p>
<p>Construct-irrelevante variantie dient in alle soorten toetsen vermeden te worden, maar door de specifieke kenmerken van ‘performance assessment’ is het risico op construct-irrelevante variantie groter. Zo kan bepaalde voorkennis van leerlingen, omwille van de complexiteit van de taken en het gebruik van hulpmiddelen zoals bijvoorbeeld een computer, een belangrijke bron van CIV zijn. Ook de inzet van beoordelaars in het scoringsproces doet het risico stijgen dat er systematisch aandacht uitgaat naar irrelevante kenmerken van prestaties van leerlingen <span class="citation" data-cites="lanePerformance2015a">(<a href="references.html#ref-lanePerformance2015a" role="doc-biblioref">S. Lane 2015</a>)</span>. Beoordelaarseffecten kunnen het resultaat zijn van toevalsfouten (bijv. in het geval de beoordelaar een ‘slechte dag’ heeft), maar kunnen ook een systematische oorzaak hebben, bijvoorbeeld wanneer beoordelaars systematisch milder zijn in hun beoordelingen. In het verleden werd bijvoorbeeld al vastgesteld dat handgeschreven schrijftaken hogere scores krijgen dan schrijftaken die met een woordprocessor zijn afgewerkt <span class="citation" data-cites="powersWill1994">(<a href="references.html#ref-powersWill1994" role="doc-biblioref">Powers et al. 1994</a>)</span>. <span class="citation" data-cites="kaneValidation2006">Kane (<a href="references.html#ref-kaneValidation2006" role="doc-biblioref">2006</a>)</span> wijst erop dat de keuze voor een welbepaalde toetsvorm, of het nu een set meerkeuzevragen of een ‘performance assessment’-taak is, ook een bron van CIV kan zijn, omdat bepaalde groepen beter presteren op bepaalde toetsvormen. In de literatuur stelden we vast dat motivatie van leerlingen een belangrijke bron van CIV is, die specifiek opspeelt in ‘low-stakes’-toetsen, zoals bijvoorbeeld toetsen met het oog op kwaliteitsmonitoring op systeemniveau. Bij toetsen waar voor de leerling in kwestie weinig op het spel staat (‘low stakes’) zijn leerlingen vaak minder gemotiveerd, waardoor geen juist beeld gevormd kan worden van het reële prestatieniveau. Deze problematiek rond lage motivatie speelt sterker bij ‘performance assessment’ dan bij klassieke toetsen samengesteld uit meerkeuzevragen, zo stellen <span class="citation" data-cites="lanePerformance2006">Suzanne Lane and Stone (<a href="references.html#ref-lanePerformance2006" role="doc-biblioref">2006</a>)</span>. Hoewel de literatuur ons op het spoor bracht van deze bron van CIV, bleek dit als dusdanig niet op te duiken in onze selectie praktijkvoorbeelden.</p>
<p>We hebben vastgesteld dat de praktijkvoorbeelden erg verschillend omspringen met construct-irrelevante variantie. Ofwel probeert men deze foutenbron ten allen prijze te vermijden, doorgaans ten koste van de authenticiteit van de toets; ofwel springt men er iets flexibeler mee om en laat men authenticiteit primeren. Concreet wordt construct-irrelevante variantie o.m. tegengegaan door (zie ook 5.2.3., voorwaarde 10):</p>
<ul>
<li>het uitgebreid testen van de taken, o.m. vanuit een evidence-centered design (5.2.3.); en</li>
<li>het inzetten van verschillende meetmethoden (o.a. <span class="citation" data-cites="messickValidity1989">S. Messick (<a href="references.html#ref-messickValidity1989" role="doc-biblioref">1989</a>)</span>; zie ook 5.2.3.).</li>
</ul>
</section>
<section id="uitdaging-4-het-opzetten-van-taken-die-recht-doen-aan-de-criteriumsituatie" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="uitdaging-4-het-opzetten-van-taken-die-recht-doen-aan-de-criteriumsituatie"><span class="header-section-number">6.4</span> Uitdaging 4: Het opzetten van taken die recht doen aan de criteriumsituatie</h2>
<p>Hoe sterker de opdrachten in de toets lijken op taken die voorkomen in de reële situaties waarin men de te toetsen competentie moet inzetten (i.e.&nbsp;de criteriumsituatie of criteriumtaken), hoe beter de toetsscores de prestatie in het competentiedomein voorspellen <span class="citation" data-cites="straetmansToetsen2014">(<a href="references.html#ref-straetmansToetsen2014" role="doc-biblioref">Straetmans 2014</a>)</span>. De mate waarin toetstaken lijken op taken in de criteriumsituatie kan zich op verschillende manieren veruitwendigen, onder meer via de inhoud en vorm van de taak of via de fysieke omgeving en sociale context waarin de taak wordt uitgevoerd <span class="citation" data-cites="gulikersToetsen2017">(<a href="references.html#ref-gulikersToetsen2017" role="doc-biblioref">Gulikers and Benthum 2017</a>)</span>.</p>
<p>‘Performance assessments’ hebben het potentieel om, via authentieke taken, complexe vaardigheden en competenties te meten. Op die manier kunnen bepaalde constructen meer volledig in kaart worden gebracht. We stellen echter vast dat het voor de geanalyseerde praktijkvoorbeelden niet steeds evident is dit potentieel waar te maken. In realiteit is het vaak zo dat complexe taken onderverdeeld worden in verschillende componenten en voor elk van deze componenten vervolgens een aparte toets wordt uitgewerkt. Aan het einde worden de scores opgeteld en deze finale score representeert dan de in kaart gebrachte ‘performance’. Zoals <span class="citation" data-cites="pecheoneWhere2015">Pecheone and Kahl (<a href="references.html#ref-pecheoneWhere2015" role="doc-biblioref">2015</a>)</span> aangeven, is dit de praktijk die in veel toetsen waar standaardisering om de hoek komt kijken, wordt gevolgd. De auteurs pleiten voor een andere, meer geïntegreerde aanpak die zij ‘criterion sampling’ noemen. Het begrip ‘criterion sampling’ is op zich eenvoudig:</p>
<blockquote class="blockquote">
<p>“(…) if you want to know what a person knows and can do, sample tasks from the domain in which she is to act, observe her performance and infer competence and learning” <span class="citation" data-cites="pecheoneWhere2015">(<a href="references.html#ref-pecheoneWhere2015" role="doc-biblioref">Pecheone and Kahl 2015, 72</a>)</span></p>
</blockquote>
<p>Verduidelijkend: deze aanpak veronderstelt dat het geheel meer is dan de optelsom van de onderdelen en dat complexe taken een integratie van bekwaamheden vereisen die niet gevat kunnen worden als ze verdeeld en gemeten worden als aparte componenten. Dat authentieke taken, of taken die recht doen aan de criteriumsituatie, vatbaar zijn voor construct-irrelevante variantie stipten we hierboven reeds aan (zie uitdaging 3). Een andere moeilijkheid is dat het opzetten van taken die recht doen aan de criteriumsituatie vaak in conflict komt met de noodzaak om te standaardiseren (zie uitdaging 2). Wanneer men in de toetsprocedure bijvoorbeeld aspecten gaat standaardiseren die niet vastgelegd zijn in de criteriumsituatie, vormt dit een bron van systematische ruis. Het gevolg is dat de resultaten niet geëxtrapoleerd kunnen worden naar het volledige competentiedomein <span class="citation" data-cites="kaneValidating2013">(<a href="references.html#ref-kaneValidating2013" role="doc-biblioref">M. T. Kane 2013</a>)</span>, met andere woorden: de taken doen geen recht doen de criteriumsituatie. We moeten dus steeds waakzaam zijn voor een (te) ver doorgedreven standaardisering. Standaardisering en authenticiteit moeten steeds onderling afgewogen. Met betrekking tot deze afweging lijkt de oplossing er op neer te komen zoveel mogelijk trouw te blijven aan de criteriumsituatie, maar terwijl ook een bepaalde graad van standaardisering en controle te behouden. Computergebaseerde toetsen dragen de mogelijkheid in zich dit evenwicht vorm te geven.</p>
<p>Om representatief te zijn voor het beoogde competentiedomein is het belangrijk dat de omstandigheden van de observatie representatief zijn voor deze in het beoogde domein <span class="citation" data-cites="kaneValidating1999">(<a href="references.html#ref-kaneValidating1999" role="doc-biblioref">Kane, Crooks, and Cohen 1999</a>)</span>. Het meenemen van de criteriumsituatie in het opzetten van de taak, betekent dus dat zowel product als proces in kaart worden gebracht. Bij de opzet van een toets schrijfvaardigheden, bijvoorbeeld, houdt dit in dat er ook ruimte moet zijn voor aspecten als voorafgaande studie van de literatuur, planning en revisie achteraf; procesgerelateerde elementen dus. <span class="citation" data-cites="powersEffects1998">Powers and Fowles (<a href="references.html#ref-powersEffects1998" role="doc-biblioref">1998</a>)</span> wijzen er met betrekking tot een toets schrijfvaardigheid echter op dat leerlingen bij een schrijftaak vaak enkel tijd hebben om een eerste ontwerp uit te schrijven, niet voor een uitvoerige planning en volgende fasen van revisie en herwerking. De taken belichten met andere woorden onvoldoende de vele processen die schrijvers gebruiken en representeren dus niet volledig de beoogde competentie (de schrijfvaardigheid in de criteriumsituatie). Ook in de praktijkvoorbeelden die we anslyseerden worden procescomponenten momenteel nog in zeer beperkte mate meegenomen. Bij computergebaseerde toetsen lijkt het inzetten van ‘tracking software’ een beloftevolle piste om zicht te krijgen op het proces. Tracking is echter een middelenintensief proces, dat niet steeds die bepaalde gegevens oplevert die bijdragen tot het beter in kaart brengen van de competentie van leerlingen.</p>
<p>Het inzetten van ‘performance assessment’ brengt een meerkost met zich mee. Daarom is het belangrijk erover te waken dat de taken en rubrics die ontwikkeld worden, ook werkelijk de volledige breedte en diepte van het beoogde construct meten. Zoals <span class="citation" data-cites="lanePerformance2015a">S. Lane (<a href="references.html#ref-lanePerformance2015a" role="doc-biblioref">2015</a>)</span> onderstreept is het immers niet omdat ‘performance assessment’ bijzonder geschikt is voor het meten van complexe constructen, dat elke ontwikkelde toetsvorm die ‘performance assessment’ omvat dit ook werkelijk doet: bewijsmateriaal is nodig om te illustreren dat de taken en rubrics werkelijk gericht zijn op het meten van dit beoogde construct. Haalbare en kwaliteitsvolle werkwijzen voor het vergaren van evidentie tijdens de pilootfase die in de praktijkvoorbeelden en de wetenschappelijke literatuur aan bod kwamen, zijn bijvoorbeeld (zie ook 5.2.7.) :</p>
<ul>
<li>het gebruik maken van cognitieve interviews;</li>
<li>het uitvoeren van een piloottest om vervolgens statistisch na te gaan of de taken voldoen.</li>
</ul>
</section>
<section id="uitdaging-5-conform-de-doelstellingen-rapporteren" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="uitdaging-5-conform-de-doelstellingen-rapporteren"><span class="header-section-number">6.5</span> Uitdaging 5: Conform de doelstellingen rapporteren</h2>
<p>De redenen waarom een toets ontwikkeld wordt, vormen ook het raamwerk waarbinnen wordt gerapporteerd <span class="citation" data-cites="cohenTest2006">(<a href="references.html#ref-cohenTest2006" role="doc-biblioref">Cohen and Wollack 2006</a>)</span>: resultaten dienen te worden gecommuniceerd in een vorm die overeenstemt met het doel van de test. Zo is het bijvoorbeeld mogelijk om resultaten op verschillende agregatieniveaus te rapporteren: individuele leerlingen, deelnemende scholen en/of systeemniveau. Tegenover de vereisten die voortvloeien uit de doelstellingen, komt ook het aspect haalbaarheid te staan, en wel op twee manieren. Enerzijds dient het rapport klaargestoomd te worden binnen een bepaalde termijn, opdat de opdrachtgevers van de toets ook tijdig aan de slag kunnen gaan met de informatie waarover wordt gerapporteerd <span class="citation" data-cites="cohenTest2006">(<a href="references.html#ref-cohenTest2006" role="doc-biblioref">Cohen and Wollack 2006</a>)</span>. Anderzijds wordt de manier waarop men kan rapporteren ook begrensd door de kwaliteit van de toetsscores. Zo is het bijvoorbeeld niet mogelijk om betrouwbare feedback op schoolniveau te genereren indien men daar bij het vastleggen van de doelstellingen en bij de toetsopzet, (m.n. bij het bepalen van de omvang van de steekproef leerlingen) geen rekening mee hield.</p>
<p>Ruwe scores worden getransformeerd en onder de vorm van geschaalde scores gerapporteerd <span class="citation" data-cites="tanWhy2011">(<a href="references.html#ref-tanWhy2011" role="doc-biblioref">Tan and Michel 2011</a>)</span>. Onder ‘schalen’ verstaan we <em>“the process of associating numbers or other ordered indicators with the performance of examinees”</em> <span class="citation" data-cites="kolenTest2014">(<a href="references.html#ref-kolenTest2014" role="doc-biblioref">Kolen and Brennan 2014, 329</a>)</span>. Een schaal wordt initieel meestal ontwikkeld voor één toets. Indien men een schaal opnieuw wil gebruiken voor de afname van een andere toets, dient men over te gaan tot equivalering: een statistisch proces dat gebruikt wordt om scores op twee of meer toetsen aan te passen, zodat de scores onderling inwisselbaar worden <span class="citation" data-cites="kolenTest2014">(<a href="references.html#ref-kolenTest2014" role="doc-biblioref">Kolen and Brennan 2014</a>)</span>, zelfs indien de toetsen (deels) uit verschillende items en/of taken bestaan. Op die manier kunnen de ruwe scores van opeenvolgende toetsafnames op de ontwikkelde scoreschaal worden geplaatst <span class="citation" data-cites="kolenTest2014">(<a href="references.html#ref-kolenTest2014" role="doc-biblioref">Kolen and Brennan 2014</a>)</span>. In de literatuur vinden we tal van equivaleringsmodellen en -procedures terug <span class="citation" data-cites="kolenTest2014 hollandLinking2006">(o.a. <a href="references.html#ref-kolenTest2014" role="doc-biblioref">Kolen and Brennan 2014</a>; <a href="references.html#ref-hollandLinking2006" role="doc-biblioref">Holland and DePascale 2006</a>)</span>.</p>
<p>Bij de analyse van de praktijkvoorbeelden viel op dat men zeer frequent item respons theorie (IRT) gebruikt, zowel om te schalen als met het oog op equivalering. IRT-modellen zijn statistische modellen die gebruikt kunnen worden om de ‘performance’ op een toets te schatten, waarbij gebruik wordt gemaakt van karakteristieken, van zowel personen als items, waarop de performance verondersteld gebaseerd te zijn <span class="citation" data-cites="lanePerformance2006">(<a href="references.html#ref-lanePerformance2006" role="doc-biblioref">Suzanne Lane and Stone 2006</a>)</span>. De focus op IRT is in de bestudeerde praktijkvoorbeelden soms zelfs bepalend voor het toetsdesign.</p>
<p><span class="citation" data-cites="daveyPsychometric2015">Davey et al. (<a href="references.html#ref-daveyPsychometric2015" role="doc-biblioref">2015</a>)</span> verwijzen naar een paper van <span class="citation" data-cites="gorinInherent2013">Gorin and Mislevy (<a href="references.html#ref-gorinInherent2013" role="doc-biblioref">2013</a>)</span> waarin de auteurs twee centrale, psychometrische uitdagingen ten aanzien van het gebruik van IRT samenvatten. Een eerste uitdaging houdt verband met de gewenste lokale onafhankelijkheid (‘local independence’) van items en/of taken, wat impliceert dat toetsvragen/activiteiten idealiter niet met elkaar in verband mogen staan. Typerend voor ‘performance assessment’ is echter dat het taaktypes inschakelt, waarvan de toetsvragen/activiteiten net verband houden met elkaar, om op die manier voor de leerling een betekenisvol geheel te kunnen vormen. De tweede centrale psychometrische knoop die met het oog op het inzetten van IRT ontward dient te worden, houdt verband met de assumptie van ‘unidimensionaliteit’. Dit betekent dat het psychometrische model best werkt wanneer een toets slechts één construct meet. ‘performance assessment’ houdt ook op dat punt bepaalde risico’s in, in die zin dat het ingezet wordt om bredere constructen te meten waarbinnen veel verschillende elementen onderscheiden kunnen worden. Naast deze beide centrale psychometrische uitdagingen, is het feit dat de meeste equivaleringsdesigns steunen op het hergebruik van minstens een aantal van de gebruikte taken (‘ankertaken’), eveneens problematisch voor de toepassing van IRT op toetsen die een ‘performance assessment’-component bevatten. ‘performance assessment’-taken zijn immers vaak makkelijk te memoriseren door leerlingen en kunnen daarom moeilijker gebruikt worden als link tussen verschillende afnames van een toets. In het geval de voorwaarden van IRT geschonden (zullen) worden, stelden we in de praktijkvoorbeelden overigens vast dat men zich beperkt tot het rapporteren van beschrijvende resultaten. Gegeven dat IRT, specifiek voor ‘performance assessment’, enkele psychometrische uitdagingen met zich meebrengt, kan men overwegen om (bijkomend) andere technieken in te zetten, zoals bijvoorbeeld comparatieve beoordeling of paarsgewijze vergelijking <span class="citation" data-cites="heldsingerUsing2010 heldsingerUsing2013 lesterhuisComparative2017">(<a href="references.html#ref-heldsingerUsing2010" role="doc-biblioref">Heldsinger and Humphry 2010</a>; <a href="references.html#ref-heldsingerUsing2013" role="doc-biblioref">S. Heldsinger and Humphry 2013</a>; <a href="references.html#ref-lesterhuisComparative2017" role="doc-biblioref">Lesterhuis et al. 2017</a>)</span>.</p>
<p>Om een valide interpretatie (en gebruik) van scores te ondersteunen, moeten er ook beslissingen genomen worden over hoe de geschaalde scores ook betekenisvol gemaakt kunnen worden. De literatuur onderscheidt hiertoe drie soorten procedures: ‘item mapping’, ‘scale anchoring’ en ‘standard setting’ <span class="citation" data-cites="kolenScaling2006a mazzeoMonitoring2006">(<a href="references.html#ref-kolenScaling2006a" role="doc-biblioref">Kolen 2006</a>; <a href="references.html#ref-mazzeoMonitoring2006" role="doc-biblioref">Mazzeo and Zieky 2006</a>)</span> (zie 5.2.7.). Het gebruik van prestatiestandaarden is wat dit betreft een interessante manier, met name om te kunnen inschatten welk aandeel van de leerlingenpopulatie een bepaalde cesuur of minimumstandaard haalt. De nood aan nieuwe, empirisch onderbouwde methoden voor het vastleggen van prestatiestandaarden met betrekking tot ‘performance assessment’ wordt al lang gesignaleerd. Onder andere uit de literatuurstudie valt echter af te leiden dat aan deze oproep slechts beperkt gevolg werd gegeven. Ook bij de analyse van de praktijkvoorbeelden stelden we vast dat innovatieve werkwijzen nog niet zijn uitgewerkt of grondig onderzocht werden.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-aeraStandards2014" class="csl-entry" role="doc-biblioentry">
AERA APA &amp; NCME. 2014. <em>Standards for <span>Educational</span> and <span>Psychological Testing</span></em>. <span>Washington D.C.</span>: <span>American Educational Research Association</span>. <a href="https://blackwells.co.uk/bookshop/product/Standards-for-Educational-and-Psychological-Testing-by-American-Educational-Research-Association-American-Psychological-Association-National-Council-on-Measurement-in-Education-Joint-Committee-on-Standards-for-Educational-and-Psychological-Testing-U-S-/9780935302356">https://blackwells.co.uk/bookshop/product/Standards-for-Educational-and-Psychological-Testing-by-American-Educational-Research-Association-American-Psychological-Association-National-Council-on-Measurement-in-Education-Joint-Committee-on-Standards-for-Educational-and-Psychological-Testing-U-S-/9780935302356</a>.
</div>
<div id="ref-brennan1995" class="csl-entry" role="doc-biblioentry">
Brennan, Robert L., and Eugene G . Johnson. 1995. <span>“Generalizability of <span>Performance Assessments</span>.”</span> <em>Educational Measurement: Issues and Practice</em> 14 (4): 9–12. <a href="https://doi.org/10.1111/j.1745-3992.1995.tb00882.x">https://doi.org/10.1111/j.1745-3992.1995.tb00882.x</a>.
</div>
<div id="ref-cohenTest2006" class="csl-entry" role="doc-biblioentry">
Cohen, Allan, and James Wollack. 2006. <span>“Test Administration, Security, Scoring, and Reporting.”</span> In <em>Educational <span>Measurement</span></em>, edited by Robert L. Brennan, 4th ed., 355–86. <span>American Council on Education/Praeger</span>.
</div>
<div id="ref-curcinValidation2014" class="csl-entry" role="doc-biblioentry">
Curcin, Milja, Andrew Boyle, Tom May, and Zeeshan Rahman. 2014. <span>“A Validation Framework for Work-Based Observational Assessment in Vocational Qualifications.”</span> <span>Coventry</span>: <span>Office of Qualifications and Examinations Regulation</span>.
</div>
<div id="ref-daveyPsychometric2015" class="csl-entry" role="doc-biblioentry">
Davey, Tim, Steve Ferrara, P. W. Holland, Rich Shavelson, Noreen M. Webb, and Lauress L. Wise. 2015. <span>“Psychometric Considerations for the Next Generation of Performance Assessment. <span>Princeton</span>.”</span> <span>Educational Testing Service</span>.
</div>
<div id="ref-gorinInherent2013" class="csl-entry" role="doc-biblioentry">
Gorin, Joanna S, and Robert J Mislevy. 2013. <span>“Inherent <span>Measurement Challenges</span> in the <span>Next Generation Science Standards</span> for <span>Both Formative</span> and <span>Summative Assessment</span>.”</span> <span>New Jersey</span>: <span>Educational Testing Service</span>. <a href="https://www.ets.org/Media/Research/pdf/gorin-mislevy.pdf">https://www.ets.org/Media/Research/pdf/gorin-mislevy.pdf</a>.
</div>
<div id="ref-gulikersToetsen2017" class="csl-entry" role="doc-biblioentry">
Gulikers, Judith, and Niek van Benthum. 2017. <span>“Toetsen van competenties.”</span> In <em>Toetsen in het hoger onderwijs</em>, edited by Henk van Berkel, Anneke Bax, and Desirée Joosten-ten Brinke, 227–39. <span>Houten</span>: <span>Bohn Stafleu van Loghum</span>. <a href="https://doi.org/10.1007/978-90-368-1679-3_18">https://doi.org/10.1007/978-90-368-1679-3_18</a>.
</div>
<div id="ref-heldsingerUsing2013" class="csl-entry" role="doc-biblioentry">
Heldsinger, S., and Humphry. 2013. <span>“Using Calibrated Exemplars in the Teacher-Assessment of Writing: An Empirical Study.”</span> <em>Educational Research</em> 55 (3): 219–35. <a href="https://doi.org/10.1080/00131881.2013.825159">https://doi.org/10.1080/00131881.2013.825159</a>.
</div>
<div id="ref-heldsingerUsing2010" class="csl-entry" role="doc-biblioentry">
Heldsinger, and Humphry. 2010. <span>“Using the Method of Pairwise Comparison to Obtain Reliable Teacher Assessments.”</span> <em>The Australian Educational Researcher</em> 37 (2): 1–19. <a href="https://doi.org/10.1007/BF03216919">https://doi.org/10.1007/BF03216919</a>.
</div>
<div id="ref-hollandLinking2006" class="csl-entry" role="doc-biblioentry">
Holland, P. W., and Charles A. DePascale. 2006. <span>“Linking and Equation.”</span> In <em>Educational <span>Measurement</span></em>, by Robert L. Brennan, 4th ed., 187–220. <span>Westport</span>: <span>Praeger Publishers</span>.
</div>
<div id="ref-johnsonAssessing2009" class="csl-entry" role="doc-biblioentry">
Johnson, Robert L., James A. Penny, and Belita Gordon. 2009. <em>Assessing Performance: Designing, Scoring, and Validating Performance Tasks</em>. <span>New York</span>: <span>The Guilford Press</span>.
</div>
<div id="ref-kaneValidation2006" class="csl-entry" role="doc-biblioentry">
Kane. 2006. <span>“Validation.”</span> In <em>Educational <span>Measurement</span></em>, by Robert L. Brennan, 4th ed. <span>Westport</span>: <span>Praeger Publishers</span>.
</div>
<div id="ref-kaneValidating2013" class="csl-entry" role="doc-biblioentry">
Kane, M. T. 2013. <span>“Validating the <span>Interpretations</span> and <span>Uses</span> of <span>Test Scores</span>.”</span> <em>Journal of Educational Measurement</em> 50 (1): 1–73. <a href="https://doi.org/10.1111/jedm.12000">https://doi.org/10.1111/jedm.12000</a>.
</div>
<div id="ref-kaneValidating1999" class="csl-entry" role="doc-biblioentry">
Kane, Crooks, and Cohen. 1999. <span>“Validating <span>Measures</span> of <span>Performance</span>.”</span> <em>Educational Measurement: Issues and Practice</em> 18 (2): 5–17. <a href="https://doi.org/10.1111/j.1745-3992.1999.tb00010.x">https://doi.org/10.1111/j.1745-3992.1999.tb00010.x</a>.
</div>
<div id="ref-kolenScaling2006a" class="csl-entry" role="doc-biblioentry">
Kolen. 2006. <span>“Scaling and Norming.”</span> In <em>Educational <span>Measurement</span></em>, by Robert L. Brennan, 4th ed. <span>Westport</span>: <span>Praeger Publishers</span>.
</div>
<div id="ref-kolenTest2014" class="csl-entry" role="doc-biblioentry">
Kolen, and Brennan. 2014. <em>Test Equating, Scaling, and Linking: Methods and Practices</em>. 3d edition. Statistics for Social Science and Public Policy. <span>New York</span>: <span>Springer</span>.
</div>
<div id="ref-lanePerformance2015a" class="csl-entry" role="doc-biblioentry">
Lane, S. 2015. <span>“Performance <span>Assessment</span>: <span>The State</span> of the <span>Art</span>.”</span> In <em>Beyond the <span>Bubble Test</span></em>, edited by Linda Darling-Hammond and Frank Adamson, 131–84. <span>San Francisco</span>: <span>John Wiley &amp; Sons, Inc.</span> <a href="https://doi.org/10.1002/9781119210863.ch5">https://doi.org/10.1002/9781119210863.ch5</a>.
</div>
<div id="ref-lanePerformance2006" class="csl-entry" role="doc-biblioentry">
Lane, Suzanne, and C. Stone. 2006. <span>“Performance <span>Assessment</span>.”</span> In <em>Educational <span>Measurement</span></em>, edited by Robert L. Brennan, 4th ed., 387–432. <span>American Council on Education/Praeger</span>.
</div>
<div id="ref-lesterhuisCompententies2015" class="csl-entry" role="doc-biblioentry">
Lesterhuis, Donche, De Maeyer, van Daal, Van Gasse, Coertjens, Verhavert, Mortier, Coenen, and Vlerick. 2015. <span>“Compententies Kwaliteitsvol Beoordelen: Brengt Een Comparatieve Aanpak Soelaas?”</span> <em>Tijdschrift Voor Hoger Onderwijs</em> 33 (2): 55–67.
</div>
<div id="ref-lesterhuisComparative2017" class="csl-entry" role="doc-biblioentry">
Lesterhuis, Verhavert, Coertjens, Donche, and De Maeyer. 2017. <span>“Comparative Judgement as a Promising Alternative to Score Competences.”</span> In <em>Innovative <span>Practices</span> for <span>Higher Education Assessment</span> and <span>Measurement</span></em>, by E. Cano and G. Ion, 119–36. <a href="https://doi.org/10.4018/978-1-5225-0531-0.ch007">https://doi.org/10.4018/978-1-5225-0531-0.ch007</a>.
</div>
<div id="ref-mazzeoMonitoring2006" class="csl-entry" role="doc-biblioentry">
Mazzeo, J., and M. J. Zieky. 2006. <span>“Monitoring <span>Educational Progress</span> with <span>Group-Score Assessments</span>.”</span> In <em>Educational <span>Measurement</span></em>, by Robert L. Brennan, 4th ed., 681–99. <span>Westport</span>: <span>Praeger Publishers</span>.
</div>
<div id="ref-messickValidity1989" class="csl-entry" role="doc-biblioentry">
Messick, S. 1989. <span>“Validity.”</span> In <em>Educational Measurement, 3rd Ed</em>, edited by R. L. Linn, 13–103. The <span>American Council</span> on <span>Education</span>/<span>Macmillan</span> Series on Higher Education. <span>American Council on Education</span>.
</div>
<div id="ref-messickInterplay1994" class="csl-entry" role="doc-biblioentry">
Messick, Samuel. 1994. <span>“The <span>Interplay</span> of <span>Evidence</span> and <span>Consequences</span> in the <span>Validation</span> of <span>Performance Assessments</span>.”</span> <em>Educational Researcher</em> 23 (2): 13–23. <a href="https://doi.org/10.3102/0013189X023002013">https://doi.org/10.3102/0013189X023002013</a>.
</div>
<div id="ref-nationalresearchcouncilDeveloping2014" class="csl-entry" role="doc-biblioentry">
National Research Council. 2014. <em>Developing <span>Assessments</span> for the <span>Next Generation Science Standards</span>. <span>Committee</span> on <span>Developing Assessments</span> of <span>Science Proficiency</span> in <span>K-12</span></em>. <span>Washington D.C.</span>: <span>The National Academies Press</span>.
</div>
<div id="ref-pecheoneWhere2015" class="csl-entry" role="doc-biblioentry">
Pecheone, Raymond, and Stuart Kahl. 2015. <span>“Where <span>We Are Now</span>.”</span> In <em>Beyond the <span>Bubble Test</span></em>, 53–91. <span>John Wiley &amp; Sons, Ltd</span>. <a href="https://doi.org/10.1002/9781119210863.ch3">https://doi.org/10.1002/9781119210863.ch3</a>.
</div>
<div id="ref-powersEffects1998" class="csl-entry" role="doc-biblioentry">
Powers, Donald E., and Mary E. Fowles. 1998. <span>“Effects of <span>Preexamination Disclosure</span> of <span>Essay Topics</span>.”</span> <em>Applied Measurement in Education</em> 11 (2): 139–57. <a href="https://doi.org/10.1207/s15324818ame1102_2">https://doi.org/10.1207/s15324818ame1102_2</a>.
</div>
<div id="ref-powersWill1994" class="csl-entry" role="doc-biblioentry">
Powers, Donald E., Mary E. Fowles, Marisa Farnum, and Paul Ramsey. 1994. <span>“Will <span>They Think Less</span> of <span>My Handwritten Essay If Others Word Process Theirs</span>? <span>Effects</span> on <span>Essay Scores</span> of <span>Intermingling Handwritten</span> and <span>Word-Processed Essays</span>.”</span> <em>Journal of Educational Measurement</em> 31 (3): 220–33. <a href="https://www.jstor.org/stable/1435267">https://www.jstor.org/stable/1435267</a>.
</div>
<div id="ref-shavelsonMeasurement2010" class="csl-entry" role="doc-biblioentry">
Shavelson, Richard J. 2010. <span>“On the Measurement of Competency.”</span> <em>Empirical Research in Vocational Education and Training</em> 2 (1, 1): 41–63. <a href="https://doi.org/10.1007/BF03546488">https://doi.org/10.1007/BF03546488</a>.
</div>
<div id="ref-stecherLooking2015" class="csl-entry" role="doc-biblioentry">
Stecher, Brian. 2015. <span>“Looking <span>Back</span>.”</span> In <em>Beyond the <span>Bubble Test</span></em>, 15–52. <span>John Wiley &amp; Sons, Ltd</span>. <a href="https://doi.org/10.1002/9781119210863.ch2">https://doi.org/10.1002/9781119210863.ch2</a>.
</div>
<div id="ref-straetmansToetsen2014" class="csl-entry" role="doc-biblioentry">
Straetmans, G. 2014. <span>“Toetsen met performance assessment methodieken.”</span> In <em>Toetsen in het hoger onderwijs</em>, edited by Henk van Berkel, Anneke Bax, and Desiree Joosten-ten Brinke. <span>Bohn Stafleu van Loghum</span>.
</div>
<div id="ref-tanWhy2011" class="csl-entry" role="doc-biblioentry">
Tan, Xuan, and Rochelle Michel. 2011. <span>“Why <span>Do Standardized Testing Programs Report Scaled Scores</span>?”</span> <em>ETS R&amp;D Connections</em>, no. 16: 6.
</div>
<div id="ref-vandaalValidity2019b" class="csl-entry" role="doc-biblioentry">
van Daal, Lesterhuis, Coertjens, Donche, and De Maeyer. 2019. <span>“Validity of Comparative Judgement to Assess Academic Writing: Examining Implications of Its Holistic Character and Building on a Shared Consensus.”</span> <em>Assessment in Education: Principles, Policy &amp; Practice</em> 26 (1): 59–74. <a href="https://doi.org/10.1080/0969594X.2016.1253542">https://doi.org/10.1080/0969594X.2016.1253542</a>.
</div>
</div>
</section>
</main> <!-- /main -->
<script type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    setTimeout(function() {
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./evaluatiematrix.html">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Evaluatiematrix</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./implicaties.html">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Implicaties</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022, EduBROn, www.edubron.be</div>   
  </div>
</footer>


</body></html>